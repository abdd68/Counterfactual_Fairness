{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fairml-research/Counterfactual_Fairness/blob/main/Counterfactual_Fairness_CRIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "TmE2o4fnsHHj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmE2o4fnsHHj",
    "outputId": "921c7a90-abad-460a-9dd9-f9dd28de494d"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.chdir('/codespace/fairness/Counterfactual_Fairness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5245d46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:15:41.800508Z",
     "start_time": "2024-01-09T17:15:41.775737Z"
    },
    "id": "5245d46d"
   },
   "outputs": [],
   "source": [
    "from models.functions import *\n",
    "from models.adv_vae import ADV_VAE\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h2IRVI24QQ7m",
   "metadata": {
    "id": "h2IRVI24QQ7m"
   },
   "source": [
    "### 1) **IMPORT THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e5b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:15:42.934042Z",
     "start_time": "2024-01-09T17:15:42.817974Z"
    },
    "id": "2b4e5b21"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'read_law_school' from 'data_loading.datasets' (/codespace/fairness/Counterfactual_Fairness/Counterfactual_Fairness/data_loading/datasets.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_loading\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_crimes, load_adult, read_law_school\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_dataset\u001b[39m(name, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sensitive_attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/codespace/fairness/Counterfactual_Fairness\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'read_law_school' from 'data_loading.datasets' (/codespace/fairness/Counterfactual_Fairness/Counterfactual_Fairness/data_loading/datasets.py)"
     ]
    }
   ],
   "source": [
    "from data_loading.datasets import read_dataset\n",
    "\n",
    "# split into train/test set\n",
    "#X_train, X_test, y_train, y_test, sensitive, sensitivet = train_test_split(X, y, Z, test_size=0.1, random_state=4)\n",
    "X_train, y_train, sensitive, X_test, y_test, sensitivet = read_dataset(name='crimes', fold=1)\n",
    "X_train, y_train, Z_train, X_test, y_test, Z_test, scaler, scale_df, meanYtrain, stdYtrain= Normalize(X_train, y_train, sensitive, X_test, y_test, sensitivet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZaAW6Sn2QawP",
   "metadata": {
    "id": "ZaAW6Sn2QawP"
   },
   "source": [
    "### 2) ADVERSARIAL INFERENCE\n",
    "\n",
    "a) In this part we are going to train a latent space z from X_train, y_train and the sensitive and we will try to recontruct X and Y from the latent space z and the sensitive. In addtion to that there is an adversarial model for mitigating the dependance with the sensitive attribute.\n",
    "\n",
    "b) In this scenario we have X that is between 0 and 1. Please note that if you want to adapt X for a continuous scenario you need to change this:\n",
    " - line 103 in adv_vae.py replace the BCE loss with an MSE one (F.binary_cross_entropy -> F.mse_loss)\n",
    " - line 129 in functions.py remove the sigmoid -> (torch.sigmoid(self.fc41(h3)) -> self.fc41(h3)\n",
    "\n",
    "c) You can see that the betaadv hyerparameter allows to mitigate the dependance with the sensitive (assessed with the HGR at the end of this senction 2). If betaadv =0 the HGR is superior to 0.9 !! and with a lambdaadv it is closer to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a7b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:16:12.372433Z",
     "start_time": "2024-01-09T17:15:48.240519Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e2a7b08",
    "outputId": "798f5a77-ea6b-4f21-c79f-54080682fb9f",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAE\n\u001b[0;32m---> 47\u001b[0m modelVAE\u001b[38;5;241m=\u001b[39mVAE(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     49\u001b[0m ADV_VAE_S0 \u001b[38;5;241m=\u001b[39m ADV_VAE(batch_size, epochs, seed, log_interval, device, nb_features \u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     50\u001b[0m                      model \u001b[38;5;241m=\u001b[39m modelVAE, model_adv \u001b[38;5;241m=\u001b[39m Adversarial, sizelat\u001b[38;5;241m=\u001b[39msizelat,\n\u001b[1;32m     51\u001b[0m                      betaX\u001b[38;5;241m=\u001b[39mbetaX,betaY\u001b[38;5;241m=\u001b[39mbetaY,betammd_E\u001b[38;5;241m=\u001b[39mbetammd_E,betaadv\u001b[38;5;241m=\u001b[39mbetaadv\n\u001b[1;32m     52\u001b[0m                     )\n\u001b[1;32m     53\u001b[0m ADV_VAE_S0\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, Z_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "sizelat=5\n",
    "class Adversarial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adversarial, self).__init__()\n",
    "        self.adv_fc1 = nn.Linear(sizelat, 32)\n",
    "        self.adv_fc2 = nn.Linear(32, 16)\n",
    "        self.adv_fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.adv_fc1(x)\n",
    "        x = F.tanh(x)\n",
    "        #x = F.dropout(x, p=0.8)\n",
    "        x = self.adv_fc2(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, p=0.8)\n",
    "        x = self.adv_fc3(x)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x\n",
    "from models.adv_vae import ADV_VAE\n",
    "#modelVAE=VAE(X_train.shape[1])\n",
    "from tqdm import trange\n",
    "\n",
    "batch_size=512\n",
    "epochs=100\n",
    "seed=1\n",
    "log_interval=1\n",
    "betaX = 1\n",
    "betaY = 1\n",
    "#betaKLD = 10\n",
    "betammd_E =1#1\n",
    "#betammd_F =0\n",
    "betaadv=100 #.1\n",
    "#device=\"cpu\"\n",
    "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import trange\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from models.functions import VAE\n",
    "modelVAE=VAE(X_train.shape[1])\n",
    "\n",
    "ADV_VAE_S0 = ADV_VAE(batch_size, epochs, seed, log_interval, device, nb_features =X_train.shape[1],\n",
    "                     model = modelVAE, model_adv = Adversarial, sizelat=sizelat,\n",
    "                     betaX=betaX,betaY=betaY,betammd_E=betammd_E,betaadv=betaadv\n",
    "                    )\n",
    "ADV_VAE_S0.fit(X_train, y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c0d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:19:59.287178Z",
     "start_time": "2024-01-09T17:19:59.006803Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c57c0d26",
    "outputId": "ee41be4c-55d1-49d3-ea58-05f7f094db5c"
   },
   "outputs": [],
   "source": [
    "from models.functions import HGR_NN\n",
    "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
    "datatest=torch.tensor(X_test.values).float().to(device)\n",
    "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
    "recon_X, z, recon_Y, mu, logvar = ADV_VAE_S0.predict(datatest.view(-1, datatest.shape[1]),senstest,ydatatest)\n",
    "Loss_X = F.binary_cross_entropy(recon_X, datatest.view(-1, datatest.shape[1]), reduction='mean')\n",
    "Loss_Y = F.mse_loss(recon_Y, ydatatest, reduction='mean')\n",
    "print(\"Loss_X TEST\", Loss_X.cpu().detach().numpy(), \"Loss_Y TEST\",Loss_Y.cpu().detach().numpy())\n",
    "# lambda = 0\n",
    "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
    "print(\"HGR NN Test\",HGR_NNP(senstest , z,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6df566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:01.773095Z",
     "start_time": "2024-01-09T17:20:01.469250Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f6df566",
    "outputId": "4dd709a9-7939-47fa-a3ee-760cfa890fcd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.functions import HGR_NN\n",
    "senstrain=torch.tensor(np.expand_dims(Z_train,axis = 1)).float().to(device)\n",
    "data=torch.tensor(X_train.values).float().to(device)\n",
    "ydata= Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).to(device)\n",
    "recon_X, z, recon_Y, mu, logvar = ADV_VAE_S0.predict(data.view(-1, data.shape[1]),senstrain,ydata)\n",
    "Loss_X = F.binary_cross_entropy(recon_X, data.view(-1, data.shape[1]), reduction='mean')\n",
    "Loss_Y = F.mse_loss(recon_Y, ydata, reduction='mean')\n",
    "print(\"Loss_X\", Loss_X.cpu().detach().numpy(), \"Loss_Y\",Loss_Y.cpu().detach().numpy() )\n",
    "# lambda = 0\n",
    "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
    "print(\"HGR NN Train\",HGR_NNP(senstrain , z,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VRyDb_nJS0th",
   "metadata": {
    "id": "VRyDb_nJS0th"
   },
   "source": [
    "### 2) **Unfair Predictor Model** (lambdap=0)\n",
    "\n",
    "In this second part we are now going to create a predictor model that is counterfactual \" UnFair \" --> the lambdap of penalization is equal to 0 !\n",
    "\n",
    "Please note that in the third part we are going to make the predictor model Fairer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52e485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:49.861000Z",
     "start_time": "2024-01-09T17:20:04.754188Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae52e485",
    "outputId": "117d4599-a1f9-489a-d08d-2f51b558dff1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.cf_predictor import CF_PREDICTOR\n",
    "\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "    def forward(self, x, a):\n",
    "        x = self.fc1(torch.cat([x,a],1))\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "batch_idx=0\n",
    "batch_size=256\n",
    "epochs=1000\n",
    "seed=1\n",
    "log_interval=1\n",
    "lr=0.0001\n",
    "nb=20\n",
    "lambdap=0.\n",
    "CF_PREDICTOR_S0 = CF_PREDICTOR(regressor=\"mse\",batch_size=batch_size, epochs=epochs, seed=seed, log_interval=log_interval, device=device, model = NN, lr=lr, modelVAE= ADV_VAE_S0, nb=nb, lambdap=lambdap)\n",
    "CF_PREDICTOR_S0.fit(X_train, y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac1224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:54.199727Z",
     "start_time": "2024-01-09T17:20:54.172455Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44ac1224",
    "outputId": "abd159b6-e4c0-4220-ef1e-4b7c84e99005"
   },
   "outputs": [],
   "source": [
    "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
    "datatest=torch.tensor(X_test.values).float().to(device)\n",
    "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
    "\n",
    "Yhat_test=CF_PREDICTOR_S0.predict(datatest,senstest)\n",
    "MSE_Test = F.mse_loss(Yhat_test,ydatatest)\n",
    "print(\"MSE TEST:\",MSE_Test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eac11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:55.089601Z",
     "start_time": "2024-01-09T17:20:54.870422Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06eac11e",
    "outputId": "a3575d75-8451-492c-9393-cb0635cf544e"
   },
   "outputs": [],
   "source": [
    "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nb = 1000\n",
    "Uni = np.random.uniform(Z_train.min(),Z_train.max(),nb)\n",
    "#Unif_X = torch.tensor(np.random.uniform(Z_train.min(),Z_train.max(),Z_test.shape[0]*nb), dtype=torch.float32).to(device)\n",
    "Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n",
    "data_X = torch.tensor(np.repeat(X_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "Y_X    = torch.tensor(np.repeat(y_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_aprime, z_aprime, recon_Y_aprime, mu_aprime, logvar_aprime = ADV_VAE_S0(data_X.view(-1, data_X.shape[1]),Unif_X,Y_X)\n",
    "Z_train_X = torch.tensor(np.repeat(Z_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_a, z_a, recon_Y_a, mu_a, logvar_a = ADV_VAE_S0.predict(data_X, Z_train_X , Y_X)\n",
    "\n",
    "predY_a_prime = CF_PREDICTOR_S0.predict(recon_X_aprime,Unif_X).cpu().detach().numpy()\n",
    "predY_a = CF_PREDICTOR_S0.predict(recon_X_a,Z_train_X.unsqueeze(1)).cpu().detach().numpy()\n",
    "print('CF Value:  {:9f}'.format(np.mean((predY_a_prime-predY_a)**2),8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gTLzwGi0TQIj",
   "metadata": {
    "id": "gTLzwGi0TQIj"
   },
   "source": [
    "For calculating the CF we generate 1000 possible counterfactual observations for each instance of X_test. For this, we repeat the X instances for each counterfactual and aggrate with a mean average loss.\n",
    "We observe in this scenario that the CF is pretty unfair .. we will try to mitigate this in the third part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lRp86zDCTFp-",
   "metadata": {
    "id": "lRp86zDCTFp-"
   },
   "source": [
    "### 3) **Fair Predictor Model** (lambdap=1)\n",
    "\n",
    "In this third part we are now going to create a predictor model that is counterfactual Fair.  At each batch and for each instance, we will generate 20 counterfactual observations (nb=20) from the inference model (from the step 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a789a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a4a789a",
    "outputId": "f3a7f05e-33b4-490f-caa3-3b60d3586f4f"
   },
   "outputs": [],
   "source": [
    "from models.cf_predictor import CF_PREDICTOR\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "    def forward(self, x, a):\n",
    "        x = self.fc1(torch.cat([x,a],1))\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "batch_idx=0\n",
    "batch_size=256\n",
    "epochs=1000\n",
    "seed=1\n",
    "log_interval=1\n",
    "lr=0.0001\n",
    "nb=20\n",
    "lambdap=1.\n",
    "CF_PREDICTOR_S0 = CF_PREDICTOR(regressor=\"mse\",batch_size=batch_size, epochs=epochs, seed=seed, log_interval=log_interval, device=device, model = NN, lr=lr, modelVAE= ADV_VAE_S0, nb=nb, lambdap=lambdap)\n",
    "CF_PREDICTOR_S0.fit(X_train, y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GndCq9JHTNXB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GndCq9JHTNXB",
    "outputId": "f6e81ac1-4ed7-4d22-bc4b-21a7a32732d4"
   },
   "outputs": [],
   "source": [
    "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
    "datatest=torch.tensor(X_test.values).float().to(device)\n",
    "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
    "\n",
    "Yhat_test=CF_PREDICTOR_S0.predict(datatest,senstest)\n",
    "MSE_Test = F.mse_loss(Yhat_test,ydatatest)\n",
    "print(\"MSE TEST:\",MSE_Test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wcP6j9QiTPQM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcP6j9QiTPQM",
    "outputId": "38b10a9b-07bd-4fbd-c449-2b5c818248ea"
   },
   "outputs": [],
   "source": [
    "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nb = 1000\n",
    "Uni = np.random.uniform(Z_train.min(),Z_train.max(),nb)\n",
    "#Unif_X = torch.tensor(np.random.uniform(Z_train.min(),Z_train.max(),Z_test.shape[0]*nb), dtype=torch.float32).to(device)\n",
    "Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n",
    "data_X = torch.tensor(np.repeat(X_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "Y_X    = torch.tensor(np.repeat(y_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_aprime, z_aprime, recon_Y_aprime, mu_aprime, logvar_aprime = ADV_VAE_S0(data_X.view(-1, data_X.shape[1]),Unif_X,Y_X)\n",
    "Z_train_X = torch.tensor(np.repeat(Z_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_a, z_a, recon_Y_a, mu_a, logvar_a = ADV_VAE_S0.predict(data_X, Z_train_X , Y_X)\n",
    "\n",
    "predY_a_prime = CF_PREDICTOR_S0.predict(recon_X_aprime,Unif_X).cpu().detach().numpy()\n",
    "predY_a = CF_PREDICTOR_S0.predict(recon_X_a,Z_train_X.unsqueeze(1)).cpu().detach().numpy()\n",
    "print('CF Value:  {:9f}'.format(np.mean((predY_a_prime-predY_a)**2),8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-UGnJuEpT_mq",
   "metadata": {
    "id": "-UGnJuEpT_mq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
