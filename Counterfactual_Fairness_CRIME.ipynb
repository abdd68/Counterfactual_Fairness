{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fairml-research/Counterfactual_Fairness/blob/main/Counterfactual_Fairness_CRIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "TmE2o4fnsHHj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmE2o4fnsHHj",
    "outputId": "921c7a90-abad-460a-9dd9-f9dd28de494d"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.chdir('/codespace/fairness/Counterfactual_Fairness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5245d46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:15:41.800508Z",
     "start_time": "2024-01-09T17:15:41.775737Z"
    },
    "id": "5245d46d"
   },
   "outputs": [],
   "source": [
    "from models.functions import *\n",
    "from models.adv_vae import ADV_VAE\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h2IRVI24QQ7m",
   "metadata": {
    "id": "h2IRVI24QQ7m"
   },
   "source": [
    "### 1) **IMPORT THE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e5b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:15:42.934042Z",
     "start_time": "2024-01-09T17:15:42.817974Z"
    },
    "id": "2b4e5b21"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_loading\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_dataset\n\u001b[0;32m----> 3\u001b[0m X_train, y_train, sensitive, X_test, y_test, sensitivet \u001b[38;5;241m=\u001b[39m \u001b[43mread_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcrimes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m X_train, y_train, Z_train, X_test, y_test, Z_test, scaler, scale_df, meanYtrain, stdYtrain\u001b[38;5;241m=\u001b[39m Normalize(X_train, y_train, sensitive, X_test, y_test, sensitivet)\n",
      "File \u001b[0;32m/codespace/fairness/Counterfactual_Fairness/Counterfactual_Fairness/data_loading/datasets.py:18\u001b[0m, in \u001b[0;36mread_dataset\u001b[0;34m(name, label, sensitive_attribute, fold)\u001b[0m\n\u001b[1;32m     16\u001b[0m     z_name \u001b[38;5;241m=\u001b[39m sensitive_attribute \u001b[38;5;28;01mif\u001b[39;00m sensitive_attribute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mracepctblack\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     fold_id \u001b[38;5;241m=\u001b[39m fold \u001b[38;5;28;01mif\u001b[39;00m fold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_crimes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madult\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_adult()\n",
      "File \u001b[0;32m/codespace/fairness/Counterfactual_Fairness/Counterfactual_Fairness/data_loading/datasets.py:48\u001b[0m, in \u001b[0;36mread_crimes\u001b[0;34m(label, sensitive_attribute, fold)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# shuffle\u001b[39;00m\n\u001b[1;32m     46\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 48\u001b[0m folds \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[1;32m     50\u001b[0m y \u001b[38;5;241m=\u001b[39m data[label]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     51\u001b[0m to_drop \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [label]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from data_loading.datasets import read_crimes, load_adult, read_law_school\n",
    "\n",
    "def read_dataset(name, label=None, sensitive_attribute=None, fold=None):\n",
    "    print(\"hello there\")\n",
    "    if name == 'crimes':\n",
    "        y_name = label if label is not None else 'ViolentCrimesPerPop'\n",
    "        z_name = sensitive_attribute if sensitive_attribute is not None else 'racepctblack'\n",
    "        fold_id = fold if fold is not None else 1\n",
    "        return read_crimes(label=y_name, sensitive_attribute=z_name, fold=fold_id)\n",
    "    elif name=='adult':\n",
    "        return load_adult()\n",
    "    elif name == 'law_school':\n",
    "        y_name = label if label is not None else 'ZFYA'\n",
    "        z_name = sensitive_attribute if sensitive_attribute is not None else 'race'\n",
    "        fold_id = fold if fold is not None else 1\n",
    "        return read_law_school(label=y_name, sensitive_attribute=z_name, fold=fold_id)\n",
    "    else:\n",
    "        raise NotImplemented('Dataset {} does not exists'.format(name))\n",
    "    \n",
    "X_train, y_train, sensitive, X_test, y_test, sensitivet = read_dataset(name='crimes', fold=1)\n",
    "X_train, y_train, Z_train, X_test, y_test, Z_test, scaler, scale_df, meanYtrain, stdYtrain= Normalize(X_train, y_train, sensitive, X_test, y_test, sensitivet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZaAW6Sn2QawP",
   "metadata": {
    "id": "ZaAW6Sn2QawP"
   },
   "source": [
    "### 2) ADVERSARIAL INFERENCE\n",
    "\n",
    "a) In this part we are going to train a latent space z from X_train, y_train and the sensitive and we will try to recontruct X and Y from the latent space z and the sensitive. In addtion to that there is an adversarial model for mitigating the dependance with the sensitive attribute.\n",
    "\n",
    "b) In this scenario we have X that is between 0 and 1. Please note that if you want to adapt X for a continuous scenario you need to change this:\n",
    " - line 103 in adv_vae.py replace the BCE loss with an MSE one (F.binary_cross_entropy -> F.mse_loss)\n",
    " - line 129 in functions.py remove the sigmoid -> (torch.sigmoid(self.fc41(h3)) -> self.fc41(h3)\n",
    "\n",
    "c) You can see that the betaadv hyerparameter allows to mitigate the dependance with the sensitive (assessed with the HGR at the end of this senction 2). If betaadv =0 the HGR is superior to 0.9 !! and with a lambdaadv it is closer to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a7b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:16:12.372433Z",
     "start_time": "2024-01-09T17:15:48.240519Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e2a7b08",
    "outputId": "798f5a77-ea6b-4f21-c79f-54080682fb9f",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAE\n\u001b[0;32m---> 47\u001b[0m modelVAE\u001b[38;5;241m=\u001b[39mVAE(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     49\u001b[0m ADV_VAE_S0 \u001b[38;5;241m=\u001b[39m ADV_VAE(batch_size, epochs, seed, log_interval, device, nb_features \u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     50\u001b[0m                      model \u001b[38;5;241m=\u001b[39m modelVAE, model_adv \u001b[38;5;241m=\u001b[39m Adversarial, sizelat\u001b[38;5;241m=\u001b[39msizelat,\n\u001b[1;32m     51\u001b[0m                      betaX\u001b[38;5;241m=\u001b[39mbetaX,betaY\u001b[38;5;241m=\u001b[39mbetaY,betammd_E\u001b[38;5;241m=\u001b[39mbetammd_E,betaadv\u001b[38;5;241m=\u001b[39mbetaadv\n\u001b[1;32m     52\u001b[0m                     )\n\u001b[1;32m     53\u001b[0m ADV_VAE_S0\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, Z_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "sizelat=5\n",
    "class Adversarial(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Adversarial, self).__init__()\n",
    "        self.adv_fc1 = nn.Linear(sizelat, 32)\n",
    "        self.adv_fc2 = nn.Linear(32, 16)\n",
    "        self.adv_fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.adv_fc1(x)\n",
    "        x = F.tanh(x)\n",
    "        #x = F.dropout(x, p=0.8)\n",
    "        x = self.adv_fc2(x)\n",
    "        x = F.relu(x)\n",
    "        #x = F.dropout(x, p=0.8)\n",
    "        x = self.adv_fc3(x)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x\n",
    "from models.adv_vae import ADV_VAE\n",
    "#modelVAE=VAE(X_train.shape[1])\n",
    "from tqdm import trange\n",
    "\n",
    "batch_size=512\n",
    "epochs=100\n",
    "seed=1\n",
    "log_interval=1\n",
    "betaX = 1\n",
    "betaY = 1\n",
    "#betaKLD = 10\n",
    "betammd_E =1#1\n",
    "#betammd_F =0\n",
    "betaadv=100 #.1\n",
    "#device=\"cpu\"\n",
    "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from tqdm import trange\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from models.functions import VAE\n",
    "modelVAE=VAE(X_train.shape[1])\n",
    "\n",
    "ADV_VAE_S0 = ADV_VAE(batch_size, epochs, seed, log_interval, device, nb_features =X_train.shape[1],\n",
    "                     model = modelVAE, model_adv = Adversarial, sizelat=sizelat,\n",
    "                     betaX=betaX,betaY=betaY,betammd_E=betammd_E,betaadv=betaadv\n",
    "                    )\n",
    "ADV_VAE_S0.fit(X_train, y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c0d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:19:59.287178Z",
     "start_time": "2024-01-09T17:19:59.006803Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c57c0d26",
    "outputId": "ee41be4c-55d1-49d3-ea58-05f7f094db5c"
   },
   "outputs": [],
   "source": [
    "from models.functions import HGR_NN\n",
    "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
    "datatest=torch.tensor(X_test.values).float().to(device)\n",
    "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
    "recon_X, z, recon_Y, mu, logvar = ADV_VAE_S0.predict(datatest.view(-1, datatest.shape[1]),senstest,ydatatest)\n",
    "Loss_X = F.binary_cross_entropy(recon_X, datatest.view(-1, datatest.shape[1]), reduction='mean')\n",
    "Loss_Y = F.mse_loss(recon_Y, ydatatest, reduction='mean')\n",
    "print(\"Loss_X TEST\", Loss_X.cpu().detach().numpy(), \"Loss_Y TEST\",Loss_Y.cpu().detach().numpy())\n",
    "# lambda = 0\n",
    "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
    "print(\"HGR NN Test\",HGR_NNP(senstest , z,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6df566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:01.773095Z",
     "start_time": "2024-01-09T17:20:01.469250Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f6df566",
    "outputId": "4dd709a9-7939-47fa-a3ee-760cfa890fcd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.functions import HGR_NN\n",
    "senstrain=torch.tensor(np.expand_dims(Z_train,axis = 1)).float().to(device)\n",
    "data=torch.tensor(X_train.values).float().to(device)\n",
    "ydata= Variable(torch.FloatTensor(np.expand_dims(y_train,axis = 1))).to(device)\n",
    "recon_X, z, recon_Y, mu, logvar = ADV_VAE_S0.predict(data.view(-1, data.shape[1]),senstrain,ydata)\n",
    "Loss_X = F.binary_cross_entropy(recon_X, data.view(-1, data.shape[1]), reduction='mean')\n",
    "Loss_Y = F.mse_loss(recon_Y, ydata, reduction='mean')\n",
    "print(\"Loss_X\", Loss_X.cpu().detach().numpy(), \"Loss_Y\",Loss_Y.cpu().detach().numpy() )\n",
    "# lambda = 0\n",
    "HGR_NNP = HGR_NN(Net_HGR(),Net2_HGR(),device, display=False)\n",
    "print(\"HGR NN Train\",HGR_NNP(senstrain , z,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VRyDb_nJS0th",
   "metadata": {
    "id": "VRyDb_nJS0th"
   },
   "source": [
    "### 2) **Unfair Predictor Model** (lambdap=0)\n",
    "\n",
    "In this second part we are now going to create a predictor model that is counterfactual \" UnFair \" --> the lambdap of penalization is equal to 0 !\n",
    "\n",
    "Please note that in the third part we are going to make the predictor model Fairer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52e485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:49.861000Z",
     "start_time": "2024-01-09T17:20:04.754188Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae52e485",
    "outputId": "117d4599-a1f9-489a-d08d-2f51b558dff1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from models.cf_predictor import CF_PREDICTOR\n",
    "\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "    def forward(self, x, a):\n",
    "        x = self.fc1(torch.cat([x,a],1))\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "batch_idx=0\n",
    "batch_size=256\n",
    "epochs=1000\n",
    "seed=1\n",
    "log_interval=1\n",
    "lr=0.0001\n",
    "nb=20\n",
    "lambdap=0.\n",
    "CF_PREDICTOR_S0 = CF_PREDICTOR(regressor=\"mse\",batch_size=batch_size, epochs=epochs, seed=seed, log_interval=log_interval, device=device, model = NN, lr=lr, modelVAE= ADV_VAE_S0, nb=nb, lambdap=lambdap)\n",
    "CF_PREDICTOR_S0.fit(X_train, y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac1224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:54.199727Z",
     "start_time": "2024-01-09T17:20:54.172455Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44ac1224",
    "outputId": "abd159b6-e4c0-4220-ef1e-4b7c84e99005"
   },
   "outputs": [],
   "source": [
    "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
    "datatest=torch.tensor(X_test.values).float().to(device)\n",
    "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
    "\n",
    "Yhat_test=CF_PREDICTOR_S0.predict(datatest,senstest)\n",
    "MSE_Test = F.mse_loss(Yhat_test,ydatatest)\n",
    "print(\"MSE TEST:\",MSE_Test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eac11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T17:20:55.089601Z",
     "start_time": "2024-01-09T17:20:54.870422Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06eac11e",
    "outputId": "a3575d75-8451-492c-9393-cb0635cf544e"
   },
   "outputs": [],
   "source": [
    "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nb = 1000\n",
    "Uni = np.random.uniform(Z_train.min(),Z_train.max(),nb)\n",
    "#Unif_X = torch.tensor(np.random.uniform(Z_train.min(),Z_train.max(),Z_test.shape[0]*nb), dtype=torch.float32).to(device)\n",
    "Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n",
    "data_X = torch.tensor(np.repeat(X_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "Y_X    = torch.tensor(np.repeat(y_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_aprime, z_aprime, recon_Y_aprime, mu_aprime, logvar_aprime = ADV_VAE_S0(data_X.view(-1, data_X.shape[1]),Unif_X,Y_X)\n",
    "Z_train_X = torch.tensor(np.repeat(Z_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_a, z_a, recon_Y_a, mu_a, logvar_a = ADV_VAE_S0.predict(data_X, Z_train_X , Y_X)\n",
    "\n",
    "predY_a_prime = CF_PREDICTOR_S0.predict(recon_X_aprime,Unif_X).cpu().detach().numpy()\n",
    "predY_a = CF_PREDICTOR_S0.predict(recon_X_a,Z_train_X.unsqueeze(1)).cpu().detach().numpy()\n",
    "print('CF Value:  {:9f}'.format(np.mean((predY_a_prime-predY_a)**2),8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gTLzwGi0TQIj",
   "metadata": {
    "id": "gTLzwGi0TQIj"
   },
   "source": [
    "For calculating the CF we generate 1000 possible counterfactual observations for each instance of X_test. For this, we repeat the X instances for each counterfactual and aggrate with a mean average loss.\n",
    "We observe in this scenario that the CF is pretty unfair .. we will try to mitigate this in the third part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lRp86zDCTFp-",
   "metadata": {
    "id": "lRp86zDCTFp-"
   },
   "source": [
    "### 3) **Fair Predictor Model** (lambdap=1)\n",
    "\n",
    "In this third part we are now going to create a predictor model that is counterfactual Fair.  At each batch and for each instance, we will generate 20 counterfactual observations (nb=20) from the inference model (from the step 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4a789a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a4a789a",
    "outputId": "f3a7f05e-33b4-490f-caa3-3b60d3586f4f"
   },
   "outputs": [],
   "source": [
    "from models.cf_predictor import CF_PREDICTOR\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "#device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1]+1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "    def forward(self, x, a):\n",
    "        x = self.fc1(torch.cat([x,a],1))\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "batch_idx=0\n",
    "batch_size=256\n",
    "epochs=1000\n",
    "seed=1\n",
    "log_interval=1\n",
    "lr=0.0001\n",
    "nb=20\n",
    "lambdap=1.\n",
    "CF_PREDICTOR_S0 = CF_PREDICTOR(regressor=\"mse\",batch_size=batch_size, epochs=epochs, seed=seed, log_interval=log_interval, device=device, model = NN, lr=lr, modelVAE= ADV_VAE_S0, nb=nb, lambdap=lambdap)\n",
    "CF_PREDICTOR_S0.fit(X_train, y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GndCq9JHTNXB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GndCq9JHTNXB",
    "outputId": "f6e81ac1-4ed7-4d22-bc4b-21a7a32732d4"
   },
   "outputs": [],
   "source": [
    "senstest=torch.tensor(np.expand_dims(Z_test,axis = 1)).float().to(device)\n",
    "datatest=torch.tensor(X_test.values).float().to(device)\n",
    "ydatatest= Variable(torch.FloatTensor(np.expand_dims(y_test,axis = 1))).to(device)\n",
    "\n",
    "Yhat_test=CF_PREDICTOR_S0.predict(datatest,senstest)\n",
    "MSE_Test = F.mse_loss(Yhat_test,ydatatest)\n",
    "print(\"MSE TEST:\",MSE_Test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wcP6j9QiTPQM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcP6j9QiTPQM",
    "outputId": "38b10a9b-07bd-4fbd-c449-2b5c818248ea"
   },
   "outputs": [],
   "source": [
    "device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "nb = 1000\n",
    "Uni = np.random.uniform(Z_train.min(),Z_train.max(),nb)\n",
    "#Unif_X = torch.tensor(np.random.uniform(Z_train.min(),Z_train.max(),Z_test.shape[0]*nb), dtype=torch.float32).to(device)\n",
    "Unif_X = torch.tensor(torch.tensor(np.expand_dims(Uni,axis=1)).repeat( X_test.shape[0],1), dtype=torch.float32).to(device)\n",
    "data_X = torch.tensor(np.repeat(X_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "Y_X    = torch.tensor(np.repeat(y_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_aprime, z_aprime, recon_Y_aprime, mu_aprime, logvar_aprime = ADV_VAE_S0(data_X.view(-1, data_X.shape[1]),Unif_X,Y_X)\n",
    "Z_train_X = torch.tensor(np.repeat(Z_test.values, nb,0), dtype=torch.float32).to(device)\n",
    "recon_X_a, z_a, recon_Y_a, mu_a, logvar_a = ADV_VAE_S0.predict(data_X, Z_train_X , Y_X)\n",
    "\n",
    "predY_a_prime = CF_PREDICTOR_S0.predict(recon_X_aprime,Unif_X).cpu().detach().numpy()\n",
    "predY_a = CF_PREDICTOR_S0.predict(recon_X_a,Z_train_X.unsqueeze(1)).cpu().detach().numpy()\n",
    "print('CF Value:  {:9f}'.format(np.mean((predY_a_prime-predY_a)**2),8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-UGnJuEpT_mq",
   "metadata": {
    "id": "-UGnJuEpT_mq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
